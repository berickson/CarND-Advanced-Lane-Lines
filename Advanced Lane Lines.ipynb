{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Brian Erickson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Abstract\n",
    "This project aims to find the position of a car in the lane along with the curvature of the road by using advanced lane line finding tecniques.  This is an extension of the earlier lane finding project.  My work for that project is at https://github.com/berickson/CarND-LaneLines-P1 and you can view the notebook at http://nbviewer.jupyter.org/github/berickson/CarND-LaneLines-P1/blob/master/P1.ipynb.  This is all imlemented as part of the Udacity Self Driving Car Nanodegree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython import display\n",
    "import glob\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Compute the camera calibration matrix and distortion coefficients given a set of chessboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "calibration_images = glob.glob('camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_videos = [\"project_video.mp4\", \"challenge_video.mp4\", \"harder_challenge_video.mp4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_images = glob.glob('test_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Camera:\n",
    "    def __init__(self):\n",
    "        self.calibrated = False\n",
    "        \n",
    "    def calibrate(self, show_annoted = False, show_corrected = False):\n",
    "        w=9\n",
    "        h=6\n",
    "        pattern_size = (w,h)\n",
    "\n",
    "        # termination criteria\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "        # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "        single_object_points = np.zeros((w*h,3), np.float32)\n",
    "        single_object_points[:,:2] = np.mgrid[0:w,0:h].T.reshape(-1,2)\n",
    "\n",
    "        all_object_points = []\n",
    "        all_image_points = []\n",
    "        im_shape = None\n",
    "\n",
    "        for image_path in calibration_images:\n",
    "            im = plt.imread(image_path)\n",
    "            im_gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "            if im_shape == None:\n",
    "                im_shape = im_gray.shape[::-1]\n",
    "            found,corners = cv2.findChessboardCorners(im,(9,6),None)\n",
    "            if found==False: \n",
    "                continue\n",
    "            corners2 = cv2.cornerSubPix(im_gray,corners,(11,11),(-1,-1),criteria)\n",
    "            all_image_points.append(corners2)\n",
    "            all_object_points.append(single_object_points)\n",
    "            if show_annoted:\n",
    "                plt.figure()\n",
    "                im_annoted = cv2.drawChessboardCorners(im, pattern_size, corners2, found)\n",
    "                plt.imshow(im_annoted)\n",
    "\n",
    "        ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(all_object_points, all_image_points, im_shape,None,None)\n",
    "        self.dist_coeffs = dist_coeffs\n",
    "        self.camera_matrix = camera_matrix\n",
    "        self.calibrated = True\n",
    "        if show_corrected:\n",
    "            for image_path in calibration_images:\n",
    "                im = plt.imread(image_path)   \n",
    "                plt.figure()\n",
    "                plt.imshow(cv2.undistort(im,mtx,dst))\n",
    "    \n",
    "    def save_calibration(self, path=None):\n",
    "        if path == None:\n",
    "            path = 'camera_cal.pickle'\n",
    "        cal = {}\n",
    "        cal['dist_coeffs'] = self.dist_coeffs\n",
    "        cal['camera_matrix'] = self.camera_matrix\n",
    "        with open( path, \"wb\" )  as f:\n",
    "            pickle.dump(cal,f)\n",
    "\n",
    "    def load_calibration(self, path=None):\n",
    "        if path == None:\n",
    "            path = 'camera_cal.pickle'\n",
    "        cal = {}\n",
    "        with open( path, \"rb\" )  as f:\n",
    "            cal = pickle.load(f)\n",
    "            self.dist_coeffs = cal['dist_coeffs']\n",
    "            self.camera_matrix = cal['camera_matrix']\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "            \n",
    "    \n",
    "    def undistort(self, im):\n",
    "        if not self.calibrated:\n",
    "            self.calibrate()\n",
    "        return cv2.undistort(im,self.camera_matrix,self.dist_coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "camera = Camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not camera.load_calibration():\n",
    "    camera.calibrate()\n",
    "    camera.save_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Apply a distortion correction to raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for image_path in calibration_images:\n",
    "    im = plt.imread(image_path)\n",
    "    im_fixed = camera.undistort(im)\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"original\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(im_fixed)\n",
    "    plt.title(\"corrected\")\n",
    "    outpath = 'output_images/undistorted_'+os.path.basename(image_path)\n",
    "    plt.imsave(outpath,im_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_filename(path):\n",
    "    '''\n",
    "    returns the filename part of path, without extension\n",
    "    '''\n",
    "    return os.path.basename(path).split(\".\")[0]\n",
    "    \n",
    "get_filename('/abc/myfile.ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_images(image_paths,columns=1,width=800):\n",
    "    column = 0\n",
    "    html = \"<table><tr>\"\n",
    "    for image_path in image_paths:\n",
    "        column += 1\n",
    "        if column > columns:\n",
    "            column = 1\n",
    "            html += \"</tr><tr>\"\n",
    "        html += \"<td>\"\n",
    "        html += \"<img width={size} height={size} src='{0}'>\".format(image_path,size=width//columns)\n",
    "        html += \"<a href={0} target='_blank'>{0}</a>\".format(image_path)\n",
    "        html += \"</td>\"\n",
    "    \n",
    "    html += \"</tr></table>\"\n",
    "    display.display(display.HTML(html))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_images(glob.glob('test_images/*'),columns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "all_images = []\n",
    "for image_path in test_images:\n",
    "    im = plt.imread(image_path)\n",
    "    im_undistorted = camera.undistort(im)\n",
    "    out_path = 'output_images/undistorted_'+get_filename(image_path)+'.jpg'\n",
    "    plt.imsave(out_path, im_undistorted)\n",
    "    all_images.append(image_path)\n",
    "    all_images.append(out_path)\n",
    "\n",
    "display_images(all_images,columns=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Use color transforms, gradients, etc., to create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        if line is not None:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(img, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def print_image(img,title=None):\n",
    "    plt.figure()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_spaces = {\"HLS\": cv2.COLOR_RGB2HLS, \"HSV\": cv2.COLOR_RGB2HSV, \"YUV\":cv2.COLOR_RGB2YUV,\"LAB\":cv2.COLOR_RGB2LAB,\"RGB\":None}\n",
    "for f in glob.glob('test_images/test4.jpg'):\n",
    "    plt.figure()\n",
    "    plt.title(f)\n",
    "    im = plt.imread(f)\n",
    "    plt.imshow(im)\n",
    "    for space_name,space_conversion in color_spaces.items():\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle(space_name)\n",
    "        fig.set_size_inches(w=10,h=3)\n",
    "        im2 = cv2.cvtColor(im,space_conversion) if space_conversion else im\n",
    "        for i,c in enumerate(space_name):\n",
    "            plt.subplot(1,3,i+1)\n",
    "            plt.imshow(im2[:,:,i],cmap='gray')\n",
    "            plt.title(c)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The \"Y\" term from YUV appears to have the most constistently bright lines, both for white and yellow, let's look at this for larger images, to make sure they all seem viable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for f in glob.glob('test_images/test4.jpg'):\n",
    "    plt.figure()\n",
    "    #get Y\n",
    "    im = plt.imread(f)\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(w=10,h=5)\n",
    "\n",
    "    #plt.subplot(1,2,1)\n",
    "    plt.imshow(im[:,:,0],cmap='gray')\n",
    "    #plt.subplot(1,2,2)\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(w=10,h=5)\n",
    "    plt.imshow(cv2.cvtColor(im,cv2.COLOR_RGB2HLS)[:,:,2],cmap='gray');\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now make a video, to see how it works (turns out HL[S] wasn't good [R]GB was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lane_gray(im):\n",
    "    return im[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def video_tag(path,width=300,height=240,title=\"\"):\n",
    "    return \"\"\"\n",
    "    <div style=\"float:left;padding-left:5px\">\n",
    "    <p>{3}</p>\n",
    "    <video width=\"{1}\" height=\"{2}\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    </div>\n",
    "    \"\"\".format(path,width,height,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class SideBySideProcessor:\n",
    "    def __init__ (self, process_callback):\n",
    "        self.process_callback = process_callback\n",
    "    def process_image(self, im):\n",
    "        im_processed = self.process_callback(im)\n",
    "        im_side_by_side = np.concatenate((im, im_processed), axis=1)\n",
    "        return im_side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_videos(\n",
    "    input_videos, \n",
    "    process_function, \n",
    "    prefix, output_folder = 'output_videos', \n",
    "    overwrite=False,\n",
    "    plot=False,\n",
    "    side_by_side=False\n",
    "):\n",
    "    output_paths = []\n",
    "    if side_by_side:\n",
    "        p = SideBySideProcessor(process_function)\n",
    "        process_function = p.process_image\n",
    "\n",
    "    \n",
    "    for input_path in input_videos:\n",
    "        output_path = output_folder+\"/\"+prefix+'_'+os.path.basename(input_path)\n",
    "        output_paths.append(output_path)\n",
    "        if overwrite or not os.path.exists(output_path) or os.path.getmtime(output_path) < os.path.getmtime(input_path):\n",
    "            clip1 = VideoFileClip(input_path)\n",
    "            white_clip = clip1.fl_image(process_function) #NOTE: this function expects color images!!\n",
    "            %time white_clip.write_videofile(output_path, audio=False)\n",
    "        \n",
    "        if plot:\n",
    "            #html =  video_tag(input_path,title=input_path)\n",
    "            html = video_tag(output_path,title=output_path)\n",
    "            display.display(display.HTML(html))\n",
    "    return output_paths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "undistorted_videos = process_videos(input_videos, camera.undistort, prefix='undistorted',plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_images(input_images, process_function, prefix, output_folder = 'output_images', overwrite=True, plot=False):\n",
    "    output_paths = []\n",
    "    for input_path in input_images:\n",
    "        output_path = output_folder+\"/\"+prefix+os.path.basename(input_path)\n",
    "        output_paths.append(output_path)\n",
    "        if overwrite or not os.path.exists(output_path):\n",
    "            im=plt.imread(input_path)\n",
    "            im_processed = process_function(im)\n",
    "            plt.imsave(output_path,im_processed)\n",
    "        \n",
    "        if plot:\n",
    "            fig = plt.figure()\n",
    "            fig.set_size_inches(w=10,h=5)\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title(input_path)\n",
    "            plt.imshow(im)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title(output_path)\n",
    "            plt.imshow(im_processed,cmap='gray')\n",
    "    return output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hsl_gray_rgb(im):\n",
    "    return cv2.cvtColor(cv2.cvtColor(im,cv2.COLOR_RGB2HLS)[:,:,2],cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "process_videos(input_videos,hsl_gray_rgb,prefix='hsl_gray',plot=True,side_by_side=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lane_gray_rgb(im):\n",
    "    return cv2.cvtColor(lane_gray(im),cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_videos(input_videos,lane_gray_rgb,prefix='lane_gray',side_by_side=True ,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Apply a perspective transform to rectify binary image (\"birds-eye view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Interstate Highway standards for the U.S. Interstate Highway System uses a 12-foot (3.7 m) standard for lane width\n",
    "http://www.dot.ca.gov/trafficops/camutcd/docs/TMChapter6.pdf p.31\n",
    "\n",
    "3.66m marking, 11m between, dot between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def birds_eye(im,flags=cv2.INTER_LINEAR):\n",
    "    im_shape = (im.shape[1],im.shape[0]) # im_shape (1280, 720)\n",
    "    # polygons to warp based on eyeballing lanes in Gimp\n",
    "    src = np.array([(270,675),(615,434),(666,434),(1050,675)],dtype=np.float32)\n",
    "    #for p in src:\n",
    "    #    plt.plot(p[0],p[1],'.')\n",
    "    dst = np.array([(270,710),(270,-600),(1050,-600),(1050,710)],dtype=np.float32)\n",
    "    dst[:,0] = 0.08805 * dst[:,0] + 540 # constant makes lane width to marker spacing ratio correct\n",
    "    transform = cv2.getPerspectiveTransform(src, dst)\n",
    "    return cv2.warpPerspective(im,transform,im_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_images(test_images, birds_eye, prefix=\"birds_eye\",plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_videos(undistorted_videos, birds_eye,'birds_eye',side_by_side=True,plot=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clip_region = np.int32([[(175,675),(1200,675),(800,450),(575,450)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def threshold(gray):\n",
    "    t = np.percentile(gray,99.6)\n",
    "    _,rv= cv2.threshold(gray, t-1, 255, cv2.THRESH_BINARY)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def threshold_with_clip_region(im):\n",
    "    roi=region_of_interest(im,clip_region)\n",
    "    return threshold(lane_gray(roi))\n",
    "\n",
    "def threshold_with_clip_region_rgb(im):\n",
    "    im2=threshold_with_clip_region(im)\n",
    "    return cv2.cvtColor(im2,cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(threshold_with_clip_region_rgb(plt.imread(test_images[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "threshold_images = process_images(test_images, threshold_with_clip_region_rgb, prefix='thresh_clip', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bird_thresh_images = process_images(threshold_images, birds_eye, prefix='bird_thresh', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a=[1,4,39,2]\n",
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_lanes_on_birdseye(im, plot=False):\n",
    "    h = np.sum(im[500:,:,0],axis=0)\n",
    "    mid=600\n",
    "    x1 = np.argmax(h[0:mid])\n",
    "    x2 = np.argmax(h[mid:])+mid\n",
    "    if plot:\n",
    "        plt.axvline(x=x1,color='g')\n",
    "        plt.axvline(x=x2,color='g')\n",
    "        plt.plot(h)\n",
    "    return x1,x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_lanes_on_birdseye(im,x1,x2):\n",
    "    for x in [x1,x2]:\n",
    "        cv2.line(im,(x,0),(x,750),(0,0,255,100),thickness=3)\n",
    "    s = \"x1: {} x2: {} distance: {}\".format(x1,x2,x2-x1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(im,s,(10,100), font, 2,(255,255,255),4,cv2.LINE_AA)\n",
    "    return im\n",
    "\n",
    "def find_and_draw_lanes_on_birdseye(im):\n",
    "    x1,x2=find_lanes_on_birdseye(im)\n",
    "    draw_lanes_on_birdseye(im,x1,x2)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rows = len(bird_thresh_images)\n",
    "print(rows)\n",
    "i=0\n",
    "for image_path in bird_thresh_images:\n",
    "    im=plt.imread(image_path)\n",
    "    fig=plt.figure()\n",
    "    fig.set_size_inches(w=10,h=5*rows)\n",
    "    i += 1\n",
    "    plt.subplot(rows,2,i)\n",
    "    x1,x2=find_lanes_on_birdseye(im,plot=True)\n",
    "    i += 1\n",
    "    plt.subplot(rows,2,i)\n",
    "    draw_lanes_on_birdseye(im,x1,x2)\n",
    "    plt.imshow(im)\n",
    "    #plt.title(\"x1: {} x2: {} distance: {}\".format(x1,x2,x2-x1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_videos(input_videos,threshold_with_clip_region_rgb, prefix='thresh_clip', plot=True,side_by_side=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def birds_thresh(im):\n",
    "    return birds_eye(threshold_with_clip_region_rgb(im))\n",
    "\n",
    "birds_thresh_videos = process_videos(undistorted_videos, birds_thresh,'birds_thresh') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hist_lanes_videos = process_videos(birds_thresh_videos, find_and_draw_lanes_on_birdseye, prefix='hist_lanes',plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def grey_birds_eye_rgb(im):\n",
    "    return birds_eye(lane_gray_rgb(im))\n",
    "\n",
    "process_videos(undistorted_videos, grey_birds_eye_rgb,'grey_birds_eye',side_by_side=True,plot=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Detect lane pixels and fit to find the lane boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def oriented_gradient(img,ksize=5, debug=False, deg=0):\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_32F,dx=1,dy=0,ksize=ksize)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_32F,dx=0,dy=1,ksize=ksize)\n",
    "    oriented = sobelx + (1.0j * sobely)\n",
    "    direction = np.angle(oriented,deg=deg)\n",
    "    magnitude = np.abs(oriented)\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        plt.figure()\n",
    "        plt.title('sobelx')\n",
    "        plt.imshow(sobelx, cmap='gray')\n",
    "        plt.figure()\n",
    "        plt.title('sobely')\n",
    "        plt.imshow(sobely, cmap='gray')\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure()\n",
    "        plt.title('direction')\n",
    "        plt.imshow(direction,cmap='gray')\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure()\n",
    "        plt.title('magnitude')\n",
    "        plt.imshow(magnitude,cmap='gray')\n",
    "    return magnitude,direction\n",
    "\n",
    "\n",
    "def gradient_for_angles(magnitude,direction,theta,tolerance):\n",
    "    filter = np.logical_and(direction > theta-tolerance,direction < theta+tolerance)\n",
    "    gradient = np.multiply(filter,magnitude)\n",
    "    return gradient\n",
    "        \n",
    "def im_float_to_int(img):\n",
    "    low = np.min(img)\n",
    "    high = np.max(img)\n",
    "    out = np.uint8((np.subtract(img,low)/(high-low))*255.)\n",
    "    return out\n",
    "\n",
    "def im_int_to_binary(img, threshold = None):\n",
    "    if threshold is None:\n",
    "        threshold=np.mean(img)\n",
    "    th, dst = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return dst\n",
    "\n",
    "def show_gradient_for_angles(magnitude,direction,theta,tolerance):\n",
    "    matched = gradient_for_angles(magnitude,direction,theta,tolerance)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('matched: {} tolerance {}, max={}'.format(theta,tolerance,np.max(matched)))\n",
    "    imint = im_float_to_int(matched)\n",
    "    plt.imshow(imint,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LaneLine:\n",
    "    def __init__(self, expected_gradient=0, color=(255,255,255), name=None):\n",
    "        self.name = name\n",
    "        self.color = color\n",
    "        self.expected_gradient = expected_gradient\n",
    "        self.line = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# globals\n",
    "red = (255,0,0)\n",
    "green = (0,255,0)\n",
    "blue = (0,0,255)\n",
    "cyan = (0,255,255)\n",
    "white = (255,255,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# see http://scikit-learn.org/stable/auto_examples/linear_model/plot_ransac.html\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "def ransac_fit(x,y):\n",
    "    #print(\"x: {}\".format(x))\n",
    "    #print(\"y: {}\".format(y))\n",
    "    model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression(),residual_threshold=5)\n",
    "    model_ransac.fit(x, y)\n",
    "    return model_ransac\n",
    "\n",
    "def ransac_image(img,predict_x=True):\n",
    "    x,y = np.nonzero(img)\n",
    "    x = x.reshape(len(x),1)\n",
    "    y = y.reshape(len(y),1)\n",
    "    #print(x)\n",
    "    #print(y)\n",
    "    try:\n",
    "        if predict_x:\n",
    "            model=ransac_fit(y,x)\n",
    "        else:\n",
    "            model=ransac_fit(x,y)\n",
    "    except:\n",
    "        model = None\n",
    "    #print(\"ransac coef:{} intercept:{}\".format(model.estimator_.coef_, model.estimator_.intercept_))\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class lane_image_processor:\n",
    "    def __init__(self):\n",
    "        self.show_hough = False\n",
    "        self.use_hough = False\n",
    "        self.use_ransac = True\n",
    "        self.clip_region =  [(175,700),(1200,700),(800,450),(575,450)]\n",
    "        self.draw_clip_region = False\n",
    "        self.lane_lines = []\n",
    "        self.lane_lines.append(LaneLine(60.,red,'outer_left'))\n",
    "        #self.lane_lines.append(LaneLine(-125.,green,'inner_left'))\n",
    "        #self.lane_lines.append(LaneLine(-60.,blue,'inner_right'))\n",
    "        self.lane_lines.append(LaneLine(120.,cyan,'outer_right'))\n",
    "        \n",
    "        # calc top and bottom of region of interest\n",
    "        self.min_y = 99999\n",
    "        self.max_y = 0\n",
    "        for x,y in self.clip_region:\n",
    "            if y < self.min_y:\n",
    "                self.min_y = y\n",
    "            if y > self.max_y:\n",
    "                self.max_y = y\n",
    "        \n",
    "    \n",
    "    def process_image(self, img):\n",
    "        #img = mpimg.imread(\"test_images/solidYellowCurve.jpg\")\n",
    "        gray = lane_gray(img)\n",
    "        mag,direction = oriented_gradient(gray,deg=1)\n",
    "        #print_image(mag,'mag')\n",
    "        #print_image(direction,'direction')\n",
    "        for lane_line in self.lane_lines: # lane detectors ordered from left to right\n",
    "            #print(lane_line.expected_gradient)\n",
    "            imfloat = gradient_for_angles(mag,direction, lane_line.expected_gradient,10)\n",
    "            #print_image(imfloat, \"imfloat\")\n",
    "            imint = im_float_to_int(imfloat)\n",
    "            #print_image(imint, \"imint\")\n",
    "            imbinary = im_int_to_binary(imint,20)\n",
    "            if self.clip_region is not None:\n",
    "                imbinary = region_of_interest(imbinary,np.int32([self.clip_region]))\n",
    "            if lane_line.line is not None:\n",
    "                x1,y1,x2,y2=lane_line.line\n",
    "                #print(\"x1={} y1={} x2={} y2={}\".format(x1,y1,x2,y2))\n",
    "                gap = 25\n",
    "                clip_line = [(x1-gap,y1),(x1+gap,y1),(x2+gap,y2),(x2-gap,y2)]\n",
    "                imbinary = region_of_interest(imbinary,np.int32([clip_line]))\n",
    "            if self.draw_clip_region:\n",
    "                cv2.polylines(img, np.int32([self.clip_region]), isClosed=True, color=white, thickness=3)\n",
    "            \n",
    "            #print_image(imbinary,\"imbinary\")\n",
    "            #show_gradient_for_angles(mag,direction, theta,15)\n",
    "            if self.use_hough:\n",
    "                lines = cv2.HoughLinesP(imbinary, rho = 3, theta = 2 * math.pi/180., threshold=20, minLineLength=20, maxLineGap=3)\n",
    "                if lines is not None:\n",
    "                    if self.show_hough:\n",
    "                        draw_lines(img,lines,color)\n",
    "                    line = lane_line_from_lines(lines, self.clip_region)\n",
    "                    #print(lane_line.line)\n",
    "                    if line is not None:\n",
    "                        lane_line.line = line\n",
    "                        draw_lines(img,[[lane_line.line]],lane_line.color,thickness=4)\n",
    "\n",
    "            #do ransac prediction\n",
    "            if self.use_ransac:\n",
    "                model = ransac_image(imbinary, predict_x=False)\n",
    "                if model is not None:\n",
    "                    min_x = model.predict(self.min_y)\n",
    "                    max_x = model.predict(self.max_y)\n",
    "                    lane_line.line = (min_x, self.min_y, max_x, self.max_y);\n",
    "                    draw_lines(img,[[lane_line.line]], lane_line.color, thickness=4)\n",
    "            #print_image(imbinary,'imbinary')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "processor = lane_image_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im = plt.imread('test_images/straight_lines1.jpg')\n",
    "plt.imshow(processor.process_image(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_videos(undistorted_videos,processor.process_image,plot=True,prefix=\"lane_lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Goal: Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
